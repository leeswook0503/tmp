{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fall armyworm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leeswook0503/tmp/blob/main/Fall_armyworm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the relevant libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from IPython.display import Image as ShowImage\n",
        "\n",
        "# Keras libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization,GlobalMaxPooling2D\n",
        "from tensorflow.keras.applications.vgg16 import VGG16 #16개의 레이어를 제공하는 CNN 아키텍처(사전 훈련된 네트워크로 재사용 가능)\n",
        "from keras.preprocessing.image import ImageDataGenerator # 실시간 데이터 증식으로 텐서 이미지 데이터의 배치를 생성.(크기 조정, 회전, 확대/축소)\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "I4muo0kfPp9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "_Ag6FSHAQZky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "myfile = files.upload()"
      ],
      "metadata": {
        "id": "N9V9mDAbQadI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x2GcPQKPf04"
      },
      "outputs": [],
      "source": [
        "# Reading the data\n",
        "train_labels = pd.read_csv(\"Train1.csv\")\n",
        "# Show the first 5 rows\n",
        "train_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels['Label'].value_counts().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "YzQoVrm_Po96",
        "outputId": "1e9114eb-2dd8-48aa-fb66-09c757ac4a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3442760f50>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**가을 거위충에 영향을 받은 옥수수 작물 이미지와 그렇지 않은 이미지 데이터의 수가 비슷**"
      ],
      "metadata": {
        "id": "DEvCtNJdAfgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "myfile = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "0O-56gu5RTfn",
        "outputId": "5fe7537f-f399-4023-a89d-4a2f71fceff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf94a0ed-88aa-43de-b512-eed6bb92f233\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cf94a0ed-88aa-43de-b512-eed6bb92f233\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Images.zip to Images (1).zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracts all the files(압축 해제)\n",
        "!unzip -q Images.zip"
      ],
      "metadata": {
        "id": "Na5sULo6Qruo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import random\n",
        "import os\n",
        "# This stores the location of the data source\n",
        "data = os.listdir(\"Images\")\n",
        "# Picking random sample from data list\n",
        "sample = random.choice(data)\n",
        "# The imread method loads image from the sprcified file\n",
        "img = cv2.imread(\"Images/\"+sample)\n",
        "# The cmap parameter displays the image in gray\n",
        "plt.imshow(img, cmap=\"gray\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "l67nRW4eQwf0",
        "outputId": "784d333f-1b69-43f8-e711-f435fd377523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-b2ca44f52dbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# This stores the location of the data source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Picking random sample from data list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#0과 1을 해충에게 영향을 받았는지 여부로 대체\n",
        "train_labels[\"Label\"] = train_labels[\"Label\"].replace({0: 'notaffected', 1: 'affected'})"
      ],
      "metadata": {
        "id": "hAQYCdi9QzdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining how data is passed to the input layer (이미지 데이터가 입력 레이어로 전달되는 방식을 정의)\n",
        "image_size = 224\n",
        "input_shape = (image_size, image_size, 3) #(이미지 높이, 이미지 너비, 이미지 채널)\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "RinKyhyLeN_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
        "# include_top 매개변수는 출력 레이어를 포함할지 여부 결정, VGG16 모델의 출력 레이어가 우리의 분류 문제에 필요하지 않으므로 False\n",
        "# weights 매개변수는 모델을 초기화할 가중치 체크포인트 지정\n",
        "# input_shape 매개변수는 네트워크에 입력할 이미지 텐서의 크기\n",
        "\n",
        "for layer in pre_trained_model.layers[:15]:\n",
        "  layer.trainable = False\n",
        "for layer in pre_trained_model.layers[15:]:\n",
        "  layer.trainable = True\n",
        "last_layer = pre_trained_model.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "x = GlobalMaxPooling2D()(last_output) #GlobalMaxPooling2D - 풀링 크기가 입력 크기와 동일하게 설정되어 전체 입력의 최대값이 출력 값으로 연결되는 또 다른 풀링 유형\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(2, activation='softmax')(x)\n",
        "model = Model(pre_trained_model.input, x)\n",
        "model.compile(loss='binary_crossentropy', #이진 분류\n",
        "optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), #확률적 경사 하강법\n",
        "metrics=['accuracy']) #분류 문제이기 때문에 정확도로 설정\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AaErsPIePxN",
        "outputId": "79644343-f994-4977-9a1a-8e70751b5597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 512)              0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,978,370\n",
            "Trainable params: 7,343,106\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Input layer - 입력 레이어는 이미지를 읽음. 이미지는 3D 매트릭스로 표시. 치수는 높이, 너비 및 채널. 네트워크가 깊어질수록 너비와 높이가 줄어듦.\n",
        "2. Convolutional layer - 가장자리와 같은 이미지의 특징이 이 레이어 내에서 추출.\n",
        "3. Pooling layer - 이 레이어는 이미지 차원 크기를 줄임. 이 계층의 목적은 이미지 크기를 줄여 데이터를 처리할 때 계산 능력을 줄이는 것. 그러면 장기적으로 과적합 가능성이 줄어듦. (MaxPooling2D 레이어를 지날때마다 이미지의 크기가 줄어드는 것을 확인할 수 있음)\n",
        "4. Fully-connected layer - 이 계층은 훈련을 통해 서로 다른 범주 간의 이미지를 분류. 즉, 컨볼루션 계층의 출력으로 표시되는 고수준 기능의 비선형 조합.\n",
        "5. Output layer - 최종 레이블을 포함.(0 아니면 1)"
      ],
      "metadata": {
        "id": "JgWkwtZo-Nkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기 종료 구현\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "earlystop = EarlyStopping(patience=10)\n",
        "# ReduceLROnPlateau는 정확도 개선이 중단되었을 때 학습률을 줄이기 위한 콜백\n",
        "# patience 매개변수는 학습률이 감소한 후 개선되지 않은 에포크의 수\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',patience=2,verbose=1,factor=0.5,min_lr=0.00001)\n",
        "callbacks = [earlystop, learning_rate_reduction]"
      ],
      "metadata": {
        "id": "aq7ST-8seSGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test_split 메서드를 이용해 훈련 데이터를 훈련 데이터셋과 검증 데이터셋으로 나눔\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df,validate_df=train_test_split(train_labels,test_size=0.2,random_state=42)\n",
        "train_df = train_df.reset_index(drop='True')\n",
        "validate_df = validate_df.reset_index(drop='True')"
      ],
      "metadata": {
        "id": "wJWU0RnjeVd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate batches of tensor image data with real-time data augmentation\n",
        "# 실시간 이미지 데이터 증식으로 텐서 이미지 데이터 일괄 생성\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "\n",
        "# Categorical encodes categorical variables (범주형 변수를 인코딩하기 위해)\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "He-QFtEGeYvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are formatting the training data (훈련 데이터의 이미지 형식을 지정)\n",
        "train_datagen = ImageDataGenerator(rotation_range=15,\n",
        "                                 rescale=1./255,\n",
        "                                 shear_range=0.1,\n",
        "                                 zoom_range=0.2, # zoom range (1-0.2 to 1+0.2)\n",
        "                                 horizontal_flip=True,\n",
        "                                 width_shift_range=0.1,\n",
        "                                 height_shift_range=0.1)\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
        "                                                  directory=\"images/\",\n",
        "                                                  x_col=\"image\",\n",
        "                                                  y_col=\"target\",\n",
        "                                                  target_size=(image_size,image_size),\n",
        "                                                  class_mode='categorical',\n",
        "                                                  batch_size=15)\n",
        "\n",
        "# Here we are formatting images on the validation data (검증 데이터의 이미지 형식을 지정)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
        "                                                  directory=\"images/\",\n",
        "                                                  x_col=\"image\",\n",
        "                                                  y_col=\"target\",\n",
        "                                                  target_size=(image_size,image_size),\n",
        "                                                  class_mode='categorical',\n",
        "                                                  batch_size=15)"
      ],
      "metadata": {
        "id": "t9-ohwYfebkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 데이터 셋을 이용해 모델을 훈련시키고 이를 100 에포크 동안 실행\n",
        "epochs=100 \n",
        "total_validate = validate_df.shape[0]\n",
        "total_train = train_df.shape[0]\n",
        "history = model.fit_generator(\n",
        "    train_generator, \n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//batch_size,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        "    callbacks=callbacks)\n",
        "    \n",
        "# Here we are creating a list of pictures - we are appending images on the list.\n",
        "# target이라는 빈 리스트를 생성해서 이미지를 추가하여 사진 목록을 생성\n",
        "# Our data source is the original data before splitting to test and train data\n",
        "target=[]\n",
        "\n",
        "for i in data: #이때의 data는 테스트와 훈련 데이터로 분할하기 전의 원본 데이터 셋\n",
        "    flag=0\n",
        "    for j in df[\"image\"]:\n",
        "        if(i==j):\n",
        "            flag=1\n",
        "            break;\n",
        "        else:\n",
        "            continue\n",
        "    if(flag==0):    \n",
        "       target.append(i)"
      ],
      "metadata": {
        "id": "roMQeC4neg-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a test dataframe with images and the target is notaffected for all images\n",
        "#이미지 데이터를 사용하여 테스트 데이터 프레임을 만들고 target은 모든 이미지에 대해 notaffected 임.\n",
        "test = pd.DataFrame({\n",
        "    'image': target,\n",
        "    'target':\"notaffected\"\n",
        "})\n",
        "test.head()"
      ],
      "metadata": {
        "id": "GqXfMnzueiPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#마지막으로 모델을 테스트 데이터에 맞추기 위해 테스트 데이터를 ImageDataGenerator에 전달\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_gen.flow_from_dataframe(\n",
        "    test, \n",
        "    directory=\"images/\", \n",
        "    x_col=\"image\",\n",
        "    y_col=\"target\",\n",
        "    target_size=(image_size,image_size),\n",
        "    class_mode='categorical',\n",
        "    batch_size=15,\n",
        "    shuffle=False)\n",
        "nb_samples = test.shape[0]\n",
        "#model.predict_generator는 새로운 이미지 데이터에 대한 예측을 도움.\n",
        "#np.ceil 메서드는 nb_samples/batch_size의 결과값을 올림\n",
        "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))"
      ],
      "metadata": {
        "id": "okep2M7AekQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are converting the submission data to a dataframe\n",
        "# 위에서 예측한 결과를 저장한 predict 객체를 test 데이터 셋의 target 행에 저장.\n",
        "test[\"target\"]=predict\n",
        "\n",
        "#here we are converting to a csv file\n",
        "#test 데이터 셋을 csv 파일로 변환\n",
        "test.to_csv(\"submission.csv\",index=False)"
      ],
      "metadata": {
        "id": "e0XdqoFvemF8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}